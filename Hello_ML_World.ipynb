{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hello-ML-World.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3fsGsjf4ufN",
        "outputId": "8baea604-32bd-414b-cf40-f26ec41d7f01",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "reviews = pd.read_csv('https://raw.githubusercontent.com/mlcollege/natural-language-processing/master/data/en_reviews.csv', sep='\\t', header=None, names =['rating', 'text'])\n",
        "reviews = reviews['text'].tolist()\n",
        "print(reviews[:2])"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['A voucher to nowhere #skypickerfail 2400 out of pocket due to skypicker delays in their booking office', 'I booked with Kiwi for the first time, just a short flight from Göteborg to London. I had forgotten my middle name in the fill-out section and was quite worried I had to pay for another ticket. Dominika and Nikola resolved the situation in good time with no extra cost. Thank you very much, will be booking again!']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8xvN5r34uaq"
      },
      "source": [
        "data = '\\n'.join(map(lambda x: x.replace('\\n', ' '), reviews))\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FvA85PNi4uYP",
        "outputId": "423c70ae-a3de-4055-8a54-14ab34ecf1e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "chars = sorted(list(set(data)))\n",
        "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
        "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
        "\n",
        "print(len(chars))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "184\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4oXFEX7V4uV4"
      },
      "source": [
        "\n",
        "MAXLEN = 40\n",
        "STEP = 10\n",
        "\n",
        "sequences = []\n",
        "next_chars = []\n",
        "for i in range(0, len(data) - MAXLEN, STEP):\n",
        "    sequences.append(data[i: i + MAXLEN])\n",
        "    next_chars.append(data[i + MAXLEN])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBPW2FKW4uTC"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "X_train = np.zeros((len(sequences), MAXLEN, len(chars)), dtype=np.bool)\n",
        "y_train = np.zeros((len(sequences), len(chars)), dtype=np.bool)\n",
        "\n",
        "for i, sequences in enumerate(sequences):\n",
        "    for t, char in enumerate(sequences):\n",
        "        X_train[i, t, char_indices[char]] = 1\n",
        "        y_train[i, char_indices[next_chars[i]]] = 1"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTp0ZhNS4uNf"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "from tensorflow.python.keras.models import Sequential\n",
        "from tensorflow.python.keras.layers import Dense, Activation, LSTM\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(512, input_shape=(MAXLEN, len(chars)), dropout=0.5, return_sequences=True))\n",
        "model.add(LSTM(512, dropout=0.5))\n",
        "model.add(Dense(len(chars)))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "optimizer = RMSprop(lr=0.001)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ufTJjKqG4uKW"
      },
      "source": [
        "def sample(preds, temperature=1.0):\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UlzKXw0G4uDr"
      },
      "source": [
        "def generate(seed, temperature=1.0):\n",
        "    sentence = MAXLEN * '\\n' + seed\n",
        "    sentence = sentence[-MAXLEN:]\n",
        "    generated = seed\n",
        "\n",
        "    next_char = None\n",
        "    while next_char != '\\n':\n",
        "        X_pred = np.zeros((1, MAXLEN, len(chars)))\n",
        "        for t, char in enumerate(sentence):\n",
        "            X_pred[0, t, char_indices[char]] = 1.\n",
        "\n",
        "        y_pred = model.predict(X_pred, verbose=0)[0]\n",
        "        next_index = sample(y_pred, temperature)\n",
        "        next_char = indices_char[next_index]\n",
        "\n",
        "        generated += next_char\n",
        "        sentence = sentence[1:] + next_char\n",
        "    return generated[0:-1]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_bFsnnR4t3W",
        "outputId": "b81af176-2ba8-4dd1-8bea-4a05f59e80c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "EPOCHS = 5\n",
        "\n",
        "old_loss = None\n",
        "for iteration in range(1, EPOCHS + 1):\n",
        "    print()\n",
        "    print('-' * 50)\n",
        "    print('Iteration', iteration)\n",
        "            \n",
        "    history = model.fit(X_train, y_train, batch_size=512, epochs=1)\n",
        "    loss = history.history['loss'][0]\n",
        "    if old_loss != None and old_loss < loss:\n",
        "        print(\"Loss explosion.\")\n",
        "        break\n",
        "    old_loss = loss\n",
        "    start_index = np.random.randint(0, len(data) - MAXLEN - 1)\n",
        "    sentence = data[start_index: start_index + MAXLEN]\n",
        "    print(generate(sentence))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "--------------------------------------------------\n",
            "Iteration 1\n",
            "455/455 [==============================] - 189s 415ms/step - loss: 2.9550\n",
            "e better off buying directly from the aile DortQbeuTho his ai alaloblatin ve ao oud K thine Jangetiee og ot the hrsde baoe €h to k ri Nami t erpurergoe.  gad do tea lish Incae anl Mhive tigh gha J ali\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 2\n",
            "455/455 [==============================] - 189s 416ms/step - loss: 2.4785\n",
            "tification of a change to my flights and me suid a d ant hall so whar to the with'bgelint ond ma Kidimesckeawh 3o hesaidefirnce dicites andodeqoeselfly sicg.CS.) fhigh af who detcan so comeasominicte Vagefs ico Bo Led, and wesertitm thiog ind sase asticon- se didifisilysingini a. wita or issondationstavi coavo kair asd it hiss our and my on hodeditime.!GSot noke corpiedomata ly Wetm aes ictise Spfoa To eydel\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 3\n",
            "455/455 [==============================] - 189s 415ms/step - loss: 2.1835\n",
            "hen I arrived in Sydney - the second stome of times raedrg I wiwhing mackld for.Than I rag,ian't sonftrilnd!\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 4\n",
            "455/455 [==============================] - 189s 415ms/step - loss: 1.9801\n",
            "y issue.\n",
            "It was a pleasure booking through pernething, chat also I paesectiagely linfred saver which exrorfer I wal andne my first was with skypicker airlines. Thanks well in I was book to bofken whichin was consermert aicours on aurle Piting ghem amdia and nenten booking airlines.AThanks crange and of suce in a Man! 2!%Eur The exfarsed me bay extrabel. I'T'ant proclem on chat pyakicg to chings ald revind they are of Kiwi asofiome was fuan heipsus very vib foreg me leas beould and lave in phanked but scem. I monged with time ther disfort to Josur ameraf proflemm and and rayaits, flught. No a conlact snrvice in masen and go an. I very beelle no had me information.I I noilly buerite and I spersing. > asper and I :rople fon my politive fright bestr my bohiA might to cerp ffor sonvace booking peliradib, the colern weir anser to Jawion was very qoeiny in thr airiiniowilane no I had this i Cracus I wis priendly, I change this booking working chated was Mlan for dhem \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 5\n",
            "455/455 [==============================] - 192s 423ms/step - loss: 1.8826\n",
            "ng for some cheap flights to get from Düur'ing for tlare to Seure flight to to customer sadperomition Marmina (sne stop CK!El0 and af this of the ex frigut, the customer surpoftemy!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNkXVgpX49Mt",
        "outputId": "c0ce6667-dcd5-4b57-d1dd-e77f36f753bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!gdown https://drive.google.com/uc?id=13rphTQmq0Db01hX7ptdCMt0IIpWjEBEA\n",
        "model.load_weights(\"lstm_lm.h5\")\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=13rphTQmq0Db01hX7ptdCMt0IIpWjEBEA\n",
            "To: /content/lstm_lm.h5\n",
            "14.5MB [00:00, 54.9MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVwTO9xw5GT_",
        "outputId": "7ef9c074-3e3f-446a-874c-1826e38e8c14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "generate('The service was')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: RuntimeWarning: divide by zero encountered in log\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'The service was very helpful and kindly customer service!'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    }
  ]
}